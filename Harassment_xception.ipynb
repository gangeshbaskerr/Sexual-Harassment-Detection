{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiDY6Zefq4OS"
   },
   "source": [
    "Transfer Learning Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sexual Harassment Detection\n",
    "Sexual Harassment Detection Using a Transfer Learning method Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary modules\n",
    "### Data Processing and Manipulation\n",
    "cv2 : Used for image processing tasks<br>\n",
    "glob : Used to find file paths matching a pattern<br>\n",
    "os : Used for interacting with the operating system<br>\n",
    "numpy : Used for numerical computations and array handling<br>\n",
    "pandas : Used for data manipulation and analysis<br>\n",
    "### For Visualization\n",
    "matplotlib.pyplot : Used for plotting graphs and images<br>\n",
    "tqdm : Used to display progress bars during iterations<br>\n",
    "### For Building ML model\n",
    "keras : High-level neural networks API for building and training models<br>\n",
    "tensorflow : Deep Learning framework used as backend for Keras<br>\n",
    "sklearn : Library for machine learning tasks, such as model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "Bi2QZepIq2bv",
    "outputId": "112c7037-3435-4aa8-cf9b-9b6936b2575e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.mkdir('models')\n",
    "    \n",
    "print('TensorFlow version:', tf.__version__)\n",
    "print('Is using GPU?', tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LIvkvIihq2d2",
    "outputId": "ea367235-4b55-454b-c654-0b3f7d78d9f4"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "from scipy import stats as s\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import tensorflow.keras.applications.xception\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a CSV file\n",
    "This csv file contains two columns which has the location of the images in our dataset and the class label (0-Healthy Environment / 1-Harassment Detected) associated with it.\n",
    "\n",
    "The csv file - 'harassment_as_csv.csv' is generated as an output of 'preprocessing.ipynb'\n",
    "#### Loading \n",
    "Reads the csv file using pandas and stores it in the 'train' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pSEBIGv7q2g0",
    "outputId": "befc033f-a400-4ba3-8ae1-4d5f134ee125"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/harassment_yes\\Screenshot 2023-07-22 01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/harassment_yes\\Screenshot 2023-07-22 01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/harassment_yes\\Screenshot 2023-07-22 01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/harassment_yes\\Screenshot 2023-07-22 01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/harassment_yes\\Screenshot 2023-07-22 01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  class\n",
       "0  images/harassment_yes\\Screenshot 2023-07-22 01...      1\n",
       "1  images/harassment_yes\\Screenshot 2023-07-22 01...      1\n",
       "2  images/harassment_yes\\Screenshot 2023-07-22 01...      1\n",
       "3  images/harassment_yes\\Screenshot 2023-07-22 01...      1\n",
       "4  images/harassment_yes\\Screenshot 2023-07-22 01...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(r\"D:\\harrasment_as_csv.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Images \n",
    "This iterates through each row of the 'train' DataFrame, loads the image specified by the 'image' column.\n",
    "#### Preprocessing Steps:\n",
    "The image is resized to (224,224,3)\n",
    "\n",
    "Converts it to a NumPy array.\n",
    "\n",
    "Normalizes the pixel values to the range [0,1]\n",
    "\n",
    "These processed images are then stored in the 'train_image' list.\n",
    "This list is then converted to a NumPy array 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the load_img function from tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "e--o6tjuq2jm",
    "outputId": "f3c6b5df-2004-4347-9798-f817f7f05355",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:10<00:00, 92.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an empty list\n",
    "train_image = []\n",
    "\n",
    "# for loop to read and store frames\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # loading the image and keeping the target size as (224, 224)\n",
    "    img = load_img(train['image'][i], target_size=(224,224))\n",
    "    # converting it to array\n",
    "    img = img_to_array(img)\n",
    "    # normalizing the pixel value\n",
    "    img = img/255.0\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "\n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating Target\n",
    "Extracts the 'class' column from the 'train' DataFrame, which contains the class labels of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Segregation\n",
    "The train_test_split function splits the 'x' and 'y' into training and testing parts.\n",
    "The split is done with test size of 20% .\n",
    "\n",
    "The 'stratify' parameter ensures that the class distribution is preserved in both the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4rxqt-8zq2nL"
   },
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'get_dummies' converts the categorical class labels into one-hot enocoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5Bcf7gjhq2sL"
   },
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Pre-trained Model\n",
    "A pre-trained VGG16 model is loaded from keras with pre-trained weights on the ImageNet dataset.\n",
    "The fully connected layers at the top of the network is excluded by setting the parameter 'include_top' to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GtBngJCgq2wg"
   },
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained Xception model\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "preprocessing the training and validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training and validation images\n",
    "X_train_preprocessed = keras.applications.xception.preprocess_input(X_train)\n",
    "X_test_preprocessed = keras.applications.xception.preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features\n",
    "Here we extract features from the images in the training and testing sets using our base_model - Xception.\n",
    "The 'predict' method is applied to both sets to obtain feature vectors for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 24s 964ms/step\n",
      "7/7 [==============================] - 6s 870ms/step\n",
      "Shape of X_train_flatten: (800, 100352)\n",
      "Shape of X_test_flatten: (200, 100352)\n"
     ]
    }
   ],
   "source": [
    "# extracting features for training frames\n",
    "X_train_features = base_model.predict(X_train_preprocessed)\n",
    "\n",
    "# extracting features for validation frames\n",
    "X_test_features = base_model.predict(X_test_preprocessed)\n",
    "\n",
    "# flatten the feature arrays\n",
    "X_train_flatten = X_train_features.reshape(X_train_features.shape[0], -1)\n",
    "X_test_flatten = X_test_features.reshape(X_test_features.shape[0], -1)\n",
    "\n",
    "print(\"Shape of X_train_flatten:\", X_train_flatten.shape)\n",
    "print(\"Shape of X_test_flatten:\", X_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 25s 985ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 7, 7, 2048)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 821ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200, 7, 7, 2048)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted features are reshaped into a format suitable for feeding into the subsequent fully connected layers. This depends on the architecture of the VGG16 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "me0zcGHFq27c"
   },
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(800,7*7*2048)\n",
    "X_test = X_test.reshape(200,7*7*2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature vectors are normalized by dividing them by the maximum value of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-CBvGHggq29T",
    "outputId": "db7e1c22-fcc3-4816-e45e-0771ead34f00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 100352)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing the pixel values\n",
    "max = X_train.max()\n",
    "X_train = X_train/max\n",
    "X_test = X_test/max\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "Fully Connected(Dense) layers with ReLU activation function.\n",
    "\n",
    "Dropout Layers for regularization.\n",
    "\n",
    "Dense Layer with softmax activation for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "remqsRV8q3Ac"
   },
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(7*7*2048,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callback Definition \n",
    "A callback to save the model weights during training. It is saved in the 'weight.hdf5' file whenever the validation loss improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "_0taJOscq3CD"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compilation\n",
    "The model is compiled with a categorical cross-entropy loss function, Adam optimizer, and accuracy metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "PyG421kOq213",
    "outputId": "d305368d-4a6b-456a-ccff-9def677d8cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 1024)              102761472 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,450,754\n",
      "Trainable params: 103,450,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs,Plots and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Images\n",
    "Plot of few sample images from the dataset along with their class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3aZ5T5q3q2rN",
    "outputId": "cf61a21d-8cfb-4c50-c007-1a4877ae741d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7401 - accuracy: 0.4837 - val_loss: 0.6979 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7754 - accuracy: 0.4837 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 0.7916 - accuracy: 0.4812 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 4s 968ms/step - loss: 0.7591 - accuracy: 0.4925 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 4s 953ms/step - loss: 0.7281 - accuracy: 0.4975 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 4s 952ms/step - loss: 0.7234 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 4s 995ms/step - loss: 0.7145 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.7307 - accuracy: 0.4725 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 4s 972ms/step - loss: 0.7133 - accuracy: 0.4888 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7018 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 4s 960ms/step - loss: 0.6988 - accuracy: 0.5263 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 4s 961ms/step - loss: 0.7093 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 4s 954ms/step - loss: 0.7068 - accuracy: 0.4950 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 4s 969ms/step - loss: 0.6978 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.7009 - accuracy: 0.4925 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 4s 974ms/step - loss: 0.7020 - accuracy: 0.5088 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 4s 932ms/step - loss: 0.6994 - accuracy: 0.5250 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 0.7029 - accuracy: 0.4825 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 0.7004 - accuracy: 0.5100 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 0.7017 - accuracy: 0.4950 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 0.6959 - accuracy: 0.5050 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 0.7016 - accuracy: 0.4850 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 0.7016 - accuracy: 0.5113 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 4s 935ms/step - loss: 0.6971 - accuracy: 0.5075 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 0.7051 - accuracy: 0.4538 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 4s 938ms/step - loss: 0.6983 - accuracy: 0.5050 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 5s 1s/step - loss: 0.6933 - accuracy: 0.5175 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 4s 919ms/step - loss: 0.6933 - accuracy: 0.5300 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 0.6973 - accuracy: 0.4875 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 0.6961 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 4s 952ms/step - loss: 0.6937 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 0.6923 - accuracy: 0.5100 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 4s 935ms/step - loss: 0.6932 - accuracy: 0.5250 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 0.6998 - accuracy: 0.4988 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 4s 932ms/step - loss: 0.6964 - accuracy: 0.5088 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 4s 929ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 0.6964 - accuracy: 0.4888 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 4s 943ms/step - loss: 0.6979 - accuracy: 0.5088 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 4s 929ms/step - loss: 0.6944 - accuracy: 0.4888 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 4s 925ms/step - loss: 0.6980 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 0.6936 - accuracy: 0.5175 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 4s 938ms/step - loss: 0.6922 - accuracy: 0.5088 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 0.6943 - accuracy: 0.5113 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 4s 938ms/step - loss: 0.6937 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 4s 938ms/step - loss: 0.6952 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 4s 939ms/step - loss: 0.6927 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 0.6952 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 0.6922 - accuracy: 0.5263 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 0.6928 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 4s 976ms/step - loss: 0.6937 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 4s 978ms/step - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 4s 925ms/step - loss: 0.6929 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 4s 952ms/step - loss: 0.6933 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 0.6931 - accuracy: 0.5138 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 4s 949ms/step - loss: 0.6933 - accuracy: 0.5175 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 4s 947ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 4s 961ms/step - loss: 0.6933 - accuracy: 0.4913 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 0.6930 - accuracy: 0.5225 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 0.6930 - accuracy: 0.5113 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 0.6934 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 4s 947ms/step - loss: 0.6936 - accuracy: 0.4875 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 4s 940ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 4s 946ms/step - loss: 0.6934 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 4s 919ms/step - loss: 0.6927 - accuracy: 0.5200 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 0.6932 - accuracy: 0.5050 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 4s 917ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 4s 936ms/step - loss: 0.6933 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 0.6938 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 4s 942ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 4s 921ms/step - loss: 0.6936 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 0.6934 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 4s 961ms/step - loss: 0.6931 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 4s 986ms/step - loss: 0.6933 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 4s 978ms/step - loss: 0.6931 - accuracy: 0.5200 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 0.6930 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 4s 979ms/step - loss: 0.6930 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 4s 944ms/step - loss: 0.6931 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 0.6932 - accuracy: 0.4825 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 4s 916ms/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 4s 961ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 4s 935ms/step - loss: 0.6932 - accuracy: 0.5138 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 4s 932ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 4s 928ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 4s 956ms/step - loss: 0.6933 - accuracy: 0.4875 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 4s 960ms/step - loss: 0.6934 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 0.6932 - accuracy: 0.4863 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 4s 942ms/step - loss: 0.6933 - accuracy: 0.4712 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 4s 953ms/step - loss: 0.6930 - accuracy: 0.4837 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 4s 932ms/step - loss: 0.6933 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 4s 962ms/step - loss: 0.6928 - accuracy: 0.5238 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 4s 928ms/step - loss: 0.6934 - accuracy: 0.4863 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 4s 930ms/step - loss: 0.6933 - accuracy: 0.4663 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 0.6930 - accuracy: 0.5175 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 4s 944ms/step - loss: 0.6934 - accuracy: 0.4888 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 4s 929ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 0.6931 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 4s 935ms/step - loss: 0.6928 - accuracy: 0.5150 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 4s 921ms/step - loss: 0.6929 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 4s 920ms/step - loss: 0.6933 - accuracy: 0.5088 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 0.6928 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 4s 937ms/step - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 4s 915ms/step - loss: 0.6937 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 4s 934ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 0.6933 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 4s 946ms/step - loss: 0.6928 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 4s 952ms/step - loss: 0.6929 - accuracy: 0.5250 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6933 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 4s 976ms/step - loss: 0.6937 - accuracy: 0.4787 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6937 - accuracy: 0.4663 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 957ms/step - loss: 0.6933 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 0.6933 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 4s 948ms/step - loss: 0.6932 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 4s 931ms/step - loss: 0.6933 - accuracy: 0.4875 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 4s 943ms/step - loss: 0.6933 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 4s 949ms/step - loss: 0.6932 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 4s 979ms/step - loss: 0.6933 - accuracy: 0.4825 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 4s 975ms/step - loss: 0.6939 - accuracy: 0.4700 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 4s 988ms/step - loss: 0.6928 - accuracy: 0.5163 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 4s 953ms/step - loss: 0.6926 - accuracy: 0.5325 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 4s 939ms/step - loss: 0.6935 - accuracy: 0.4787 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 4s 977ms/step - loss: 0.6929 - accuracy: 0.5238 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 4s 964ms/step - loss: 0.6928 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6929 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6936 - accuracy: 0.4812 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6934 - accuracy: 0.4863 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 4s 986ms/step - loss: 0.6936 - accuracy: 0.4812 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 4s 967ms/step - loss: 0.6938 - accuracy: 0.4600 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 4s 969ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 4s 965ms/step - loss: 0.6929 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 4s 982ms/step - loss: 0.6933 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 4s 964ms/step - loss: 0.6931 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 4s 961ms/step - loss: 0.6936 - accuracy: 0.4800 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 4s 957ms/step - loss: 0.6930 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 4s 967ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 4s 977ms/step - loss: 0.6934 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 4s 962ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 4s 951ms/step - loss: 0.6931 - accuracy: 0.4950 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 0.6930 - accuracy: 0.5225 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 0.6935 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 4s 927ms/step - loss: 0.6934 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 4s 938ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 4s 953ms/step - loss: 0.6936 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 4s 933ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 4s 943ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 4s 913ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 4s 922ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 4s 943ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 4s 924ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 4s 920ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 4s 912ms/step - loss: 0.6930 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 4s 909ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 4s 903ms/step - loss: 0.6935 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 4s 908ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 4s 916ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 4s 899ms/step - loss: 0.6935 - accuracy: 0.4888 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 4s 947ms/step - loss: 0.6933 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 4s 916ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 4s 914ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 4s 906ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 4s 906ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 4s 915ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 4s 920ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 4s 916ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 938ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 4s 941ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 4s 974ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 4s 913ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 4s 926ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 4s 921ms/step - loss: 0.6929 - accuracy: 0.5088 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 4s 921ms/step - loss: 0.6933 - accuracy: 0.4938 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 4s 911ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 4s 913ms/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 4s 925ms/step - loss: 0.6934 - accuracy: 0.4950 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 4s 931ms/step - loss: 0.6931 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 4s 915ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 4s 918ms/step - loss: 0.6928 - accuracy: 0.5125 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6937 - accuracy: 0.4875 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 4s 947ms/step - loss: 0.6932 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 4s 955ms/step - loss: 0.6933 - accuracy: 0.4913 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 4s 957ms/step - loss: 0.6930 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 4s 970ms/step - loss: 0.6937 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 4s 954ms/step - loss: 0.6935 - accuracy: 0.5013 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 4s 983ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.6930 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 4s 995ms/step - loss: 0.6929 - accuracy: 0.5125 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 4s 930ms/step - loss: 0.6930 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 4s 958ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 4s 935ms/step - loss: 0.6933 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 4s 955ms/step - loss: 0.6933 - accuracy: 0.5038 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 4s 923ms/step - loss: 0.6930 - accuracy: 0.5075 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec4ab13910>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 32ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Test Accuracy: 50.0 \n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {scores[1]*100} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Child_Labour_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
